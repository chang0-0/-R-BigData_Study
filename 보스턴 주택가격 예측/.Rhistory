pred_glm_test = predict(model_glm, newdata = df_test, type = "response")
head(pred_glm_test)
#로지스틱 회귀 모델
model_glm <= glm(Class ~ . , data = subset(df_train, select = c(-V1, -V2)), family = "binomial")
head(model_glm)
#로지스틱 회귀 모델
model_glm <= glm(Class ~ . , data = subset(df_train, select = c(-V1, -V2)), family = "binomial")
pred_glm_test = predict(model_glm, newdata = df_test, type = "response")
head(pred_glm_test)
head(model_glm)
head(model_glm)
head(pred_glm_test)
df_train
head(df_train)
head(pred_glm_test)
levels(pred_glm_test_class)
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class)
levels(pred_glm_test_class) <- ("bad", "good")
levels(pred_glm_test_class) <- c("bad", "good")
pred_glm_test_class
#로지스틱 회귀 모델
# 로지스틱 회귀 에서는 family=binomial로 지정해주어야한다.
model_glm = glm(Class ~ . , data = subset(df_train, select = c(-V1, -V2)), family = "binomial")
pred_glm_test = predict(model_glm, newdata = df_test, type = "response")
model_glm
summary(model_glm)
model_glm
model_glm
summary(model_glm)
model_glm
head(df_train)
head(pred_glm_test)
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class) <- c("bad", "good")
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class) <- c("bad", "good")
head(pred_glm_test_class)
cfm_glm = caret::confusionMatrix(pred_glm_test_class, df_test$Class)
head(cfm_glm)
cfm_glm
library(randomForest)
model_rm = randomForest(Class ~ . , data = subset(df_train, select = c(-V1, -V2) ))
model_rf = randomForest(Class ~ . , data = subset(df_train, select = c(-V1, -V2) ))
mode_rf
head(model_rf)
pred_rf_test = predict(model_rf, newdata = df_test, type='response')
cfm_rf = caret::confusionMatrix(pred_rf_test, df_test$Class)
model_rf = randomForest(Class ~ . , data = subset(df_train, select = c(-V1, -V2) ))
pred_rf_test = predict(model_rf, newdata = df_test, type='response')
cfm_rf = caret::confusionMatrix(pred_rf_test, df_test$Class)
head(pred_rf_test)
cfm_rf
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 0, 1))
levels(pred_glm_test_class) <- c("bad", "good")
head(pred_glm_test_class)
cfm_glm = caret::confusionMatrix(pred_glm_test_class, df_test$Class)
cfm_glm
cfm_glm = caret::confusionMatrix(pred_glm_test_class, df_test$Class, positive="good")
cfm_glm
head(pred_glm_test)
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class) <- c("bad", "good")
head(pred_glm_test_class)
cfm_glm = caret::confusionMatrix(pred_glm_test_class, df_test$Class, positive="good")
cfm_glm
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class) <- c("bad", "good")
head(pred_glm_test_class)
cfm_glm = caret::confusionMatrix(pred_glm_test_class, df_test$Class, positive="good")
cfm_glm
library(randomForest)
model_rf = randomForest(Class ~ . , data = subset(df_train, select = c(-V1, -V2) ))
pred_rf_test = predict(model_rf, newdata = df_test, type='response')
cfm_rf = caret::confusionMatrix(pred_rf_test, df_test$Class)
head(pred_rf_test)
cfm_rf
cfm_rf = caret::confusionMatrix(pred_rf_test, df_test$Class, positive="good")
head(pred_rf_test)
cfm_rf
library(randomForest)
model_rf = randomForest(Class ~ . , data = subset(df_train, select = c(-V1, -V2) ))
pred_rf_test = predict(model_rf, newdata = df_test, type='response')
cfm_rf = caret::confusionMatrix(pred_rf_test, df_test$Class, positive="good")
head(pred_rf_test)
cfm_rf
library(ISLR)
install.packages("ISLR")
library(ISLR)
df = default
str(df)
str(df)
data(default)
df = default
str(df)
data(default)
data(Default)
df = Default
str(df)
class(df)
head(df)
train_idx = sample(1:nrow(bankruptcy), size=0.8*nrow(bankruptcy), replace=FALSE)
set.seed(2)
train_idx = sample(1:nrow(df), size=0.8*nrow(bankruptcy), replace=FALSE)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
tain_idx
train_idx
test_idx = -(train_idx)
test_idx
nrow(test_idx)
sum(test_idx)
sum(nrow(test_idx))
(ncol(test_idx))
n(test_idx)
idx = caret::createDataPartition(df, p=0.7)
idx
idx = caret::createDataPartition(df, p=0.7)
df_train = df[idx$Resample1, ]
df_test = df[-idx$Resample1,]
df_train
df_train = Ionosphere[idx$Resample1, ]
df_test = Ionosphere[-idx$Resample1,]
df_train
idx = caret::createDataPartition(Ionosphere$Class, p = 0.7)
df_train = Ionosphere[idx$Resample1, ]
df_test = Ionosphere[-idx$Resample1,]
df_train
idx = caret::createDataPartition(df, p=0.7)
df_train = df[idx, ]
df_test = df[-idx,]
df_train
idx = caret::createDataPartition(df, p=0.7)
df_train2 = df[idx, ]
df_test2 = df[-idx,]
df_train2
idx = caret::createDataPartition(df, p=0.8, list=FALSE)
df_train2 = df[idx, ]
df_test2 = df[-idx,]
df_train2
head(df)
idx = caret::createDataPartition(df, p=0.8, list=FALSE, replace=FALSE)
idx = caret::createDataPartition(df, p=0.8, list=FALSE)
df_train2 = df[idx, ]
df_test2 = df[-idx,]
df_train2
te = df[test_idx,]
te
te = df[test_idx,]
te
df_train2
df_test2
idx = caret::createDataPartition(Default, p=0.8, list=FALSE)
df_train2 = df[idx, ]
df_test2 = df[-idx,]
idx = caret::createDataPartition(Default, p=0.8, list=FALSE)
df_train2 = Default[idx, ]
df_test2 = Default[-idx,]
df_train2
df_test2
install.packages("car")
library(car)
vif(model_glm)
# install.packages("car")
library(car)
vif(model_glm)
summary(model_glm)
library(mlbench)
data(Ionosphere)
df = Ionosphere
idx = caret::createDataPartition(df$Class, p = 0.7)
df_train = df[idx$Resample1, ]
df_test = df[-idx$Resample1, ]
head(df_train)
#로지스틱 회귀 모델
# 로지스틱 회귀 에서는 family=binomial로 지정해주어야한다.
model_glm = glm(Class ~ . , data = subset(df_train, select = c(-V1, -V2)), family = "binomial")
# install.packages("car")
library(car)
vif(model_glm)
model_glm = step(model_glm, direction = "both")
# install.packages("car")
library(car)
vif(model_glm)
pred_glm_test = predict(model_glm, newdata = df_test, type = "response")
head(pred_glm_test)
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
levels(pred_glm_test_class) <- c("bad", "good")
head(pred_glm_test_class)
# replae = FALSE (비복원추출)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = -(train_idx)
te = df[test_idx,]
te
# install.packages("ISLR")
library(ISLR)
data(Default)
df = Default
set.seed(2)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace="FALSE")
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace="FALSE")
data(Default)
df = Default
set.seed(2)
# install.packages("ISLR")
library(ISLR)
data(Default)
df = Default
# replae = FALSE (비복원추출)
set.seed(20)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace="FALSE")
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = (-train_idx)
nrow(train_idx)
ncol(train_idx)
head(train_idx)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
df_glm = glm(df ~ ., family="binomial", datat = df_train)
df_glm = glm(Default ~ ., family="binomial", datat = df_train)
df_glm = glm(Default ~ ., family=binomial, datat = df_train)
df_glm = glm(default ~ ., family=binomial, datat = df_train)
df_glm = glm(default ~ . , family=binomial, datat = df_train)
df_glm = glm(default ~ . , family = binomial, data = df_train)
df_glm
summary(df_glm)
step_model = step(df_glm, direction="both")
summary(step_model)
null_deviance = 2354.0
null_deviance = 2333.8
residual_deviance = 1258.0
model_deviance = null_deviance - residual_deviance
model_deviance
pchisq(model_deviance, df=2, lower.tail = FALSE)
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
pred
df_pred = as.data.frame(pred)
df_pred
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default = as.factor(df_pred$default)
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default = as.factor(df_pred$default)
df_pred$default = as.factor(df_pred$default)
df_pred$default
confusionMatrix(data =df_pred$default, reference = df_test[,1])
confusionMatrix(data =df_pred$default, reference = df_test[,1])
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
library(caret)
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default = as.factor(df_pred$default)
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, 1, 0))
pred_glm_test_class = factor(ifelse(pred_glm_test >= 0.5, 1, 0))
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, 1, 0))
df_pred$default
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default = as.factor(df_pred$default)
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred = as.data.frame(pred)
df_pred
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, "Yes", "No"))
df_pred$default
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred = as.data.frame(pred)
df_pred
df_pred$default
df_pred = as.data.frame(pred)
df_pred
df_pred$default
head(df_pred)
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$default >= 0.5, "Yes", "No"))
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$default >= 0.5, "Yes", "No"))
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred = as.data.frame(pred)
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$default >= 0.5, "Yes", "No"))
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$default >= 0.5, df_pred$default = "Yes", df_pred$default = "No"))
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default = "Yes", df_pred$default = "No"))
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred = as.data.frame(pred)
df_pred
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default = "Yes", df_pred$default = "No"))
df = Default
data(Default)
df = Default
# replae = FALSE (비복원추출)
set.seed(20)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = (-train_idx)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
df_glm = glm(default ~ . , family = binomial, data = df_train)
step_model = step(df_glm, direction="both")
summary(step_model)
null_deviance = 2333.8
residual_deviance = 1258.0
model_deviance = null_deviance - residual_deviance
# df를 2로 넣어주는 이유는 Null deviance의 자유도가 7999이고, Residual의 자유도가 7997이므로
# 둘의 자유도가 2차이 나기 때문에 df=2 입니다.
pchisq(model_deviance, df=2, lower.tail = FALSE)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred = as.data.frame(pred)
df_pred
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default = as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default = "Yes", df_pred$default = "No"))
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default <- as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
df_pred$default = as.factor(df_pred$default)
df_pred$default <- as.factor(df_pred$default)
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
df_pred$default
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default <- as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
df_pred$default
str(df_pred$defaul)
str(df_pred$default)
str(df_pred)
df_pred$default <- as.factor(df_pred$default)
df_pred$default <- as.factor(df_pred$default)
df_pred$default <- as.factor(df_pred$default)
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
# 확률 0.5를 기준으로 파산 여부 변환 (Yes/No)
df_pred$default <- as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
df_pred$default <- as.factor(df_pred$default)
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred <- as.data.frame(pred)
df_pred$default <- as.data.frame(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
df_pred$default <- as.factor(df_pred$default)
vif(step_model)
pred = predict(step_model, newdata = df_test[, -1], type="response")
df_pred <- as.data.frame(pred)
df_pred$default <- as.data.factor(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
df_pred$default <- as.factor(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
caret::confusionMatrix(data =df_pred$default, reference = df_test[,1])
library(ModelMetrics)
library(ModelMetrics)
auc(actual = df_test[, 1], predict = df_pred$default)
library(ModelMetrics)
auc_model <- auc(actual = df_test[, 1], predict = df_pred$default)
# auc는 불랴의 성능능
window(auc_model)
fitted(df_pred$default)
fitted(df_pred$default)
df_pred$default <- as.factor(ifelse(df_pred$pred >= 0.5, df_pred$default <- "Yes", df_pred$default <- "No"))
de <- df_pred$default
fitted(de)
fitted(df_pred)
fitted(pred)
fitted(df_glm)
df_glm
step_model = step(df_glm, direction="both")
summary(step_model)
fitted(df_glm)
dim(df_train)
dim(df_test)
dim(Defaul)
dim(Default)
train_idx2 = caret::createDataPartition(df, p=0.8)
str(idx)
idx
idx2 = caret::createDataPartition(df, p=0.8)
idx2
idx2 = caret::createDataPartition(df, p=0.2)
idx2
idx2 = caret::createDataPartition(df, p=0.2)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
df_test2
df_train2
dim(df_test2)
dim(df_train2)
idx2 = caret::createDataPartition(df, p=0.8)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_train2)
idx2 = caret::createDataPartition(df, p=80)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_train2)
idx = caret::createDataPartition(df$Class, p = 0.7)
df_train = df[idx$Resample1, ]
df_test = df[-idx$Resample1, ]
dim(df_test)
dim(df_train)
dim(df_test2)
idx2 = caret::createDataPartition(df, p=80)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
dim(df_train2)
idx2 = createDataPartition(df, p=80)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
dim(df_train2)
idx = caret::createDataPartition(df$Class, p = 0.7)
df_train = df[idx$Resample1, ]
dim(df_test)
dim(df_train)
# replae = FALSE (비복원추출)
set.seed(20)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = (-train_idx)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
dim(df_train)
dim(df_test)
idx2 = createDataPartition(df, p=nrow(df)* 0.8)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
data(Default)
df = Default
# replae = FALSE (비복원추출)
set.seed(20)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = (-train_idx)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
idx2 = createDataPartition(df, p = 0.8 * nrow(df))
df_test2 = df[idx2$Resample1, ]
nrow(df)
idx2 = caret::createDataPartition(df, p = 0.8 * nrow(df))
idx2 = caret::createDataPartition(df, p = 0.8, list=FALSE)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
idx2 = caret::createDataPartition(df$default, p = 0.8, list=FALSE)
df_test2 = df[idx2$Resample1, ]
str(Default)
idx2 = caret::createDataPartition(df$default, p = 0.8, list=FALSE)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
idx2 = caret::createDataPartition(df$default, p = 0.8)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
dim(df_train2)
# install.packages("ISLR")
library(ISLR)
data(Default)
df = Default
# replae = FALSE (비복원추출)
set.seed(20)
train_idx = sample(1:nrow(df), size=0.8*nrow(df), replace=FALSE)
test_idx = (-train_idx)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
dim(df_train)
dim(df_test)
str(Default)
idx2 = caret::createDataPartition(df$default, p = .8, list = F)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
idx2 = caret::createDataPartition(df$default, p = .8, list = F)
idx
idx2
idx2 = caret::createDataPartition(Default$default, p = .8, list = F)
str(idx2)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
idx2 = caret::createDataPartition(Default$default, p = .8)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_test2)
dim(df_train2)
df_train = df[train_idx, ]
df_test = df[test_idx, ]
dim(df_train)
dim(df_test)
idx2 = caret::createDataPartition(Default, p = .8)
df_test2 = df[idx2$Resample1, ]
idx2 = caret::createDataPartition(Default$default, p = .8)
df_test2 = df[idx2$Resample1, ]
df_train2 = df[-idx2$Resample1, ]
dim(df_train2)
dim(df_train2)
# install.packages("skimr")
library(mlr3verse)
library(skimr)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
setwd("C:/Users/Samsung/Desktop/빅분기실기준비/보스턴 주택가격 예측")
test <- read.csv("test.csv")
train <- read.csv("train.csv")
sapply(train, FUN = function(x) {
sum(is.na(x))
})
sapply(test, FUN = function(x) {
sum(is.na(x))
})
skim(train)
